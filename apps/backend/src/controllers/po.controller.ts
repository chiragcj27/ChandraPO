import { Request, Response } from 'express';
import fs from 'fs';
import path from 'path';
import { S3Client, GetObjectCommand } from '@aws-sdk/client-s3';
import { File, PO, POItem } from '@repo/db';
import { s3Service } from '../services/s3.service';
import { fastapiService } from '../services/fastapi.service';
import type {
  ExtractedLine,
  ExtractedPOResponse,
  FileMetadata,
  PODocumentShape,
  POItemRecord,
  PurchaseOrderDTO,
  PurchaseOrderItemDTO,
} from '../types/po';

const normalizeDate = (value?: string | Date | null) => {
  if (!value) return undefined;
  const date = typeof value === 'string' ? new Date(value) : value;
  if (Number.isNaN(date.getTime())) return undefined;
  return date;
};

const formatDateForClient = (value?: Date | string | null) => {
  if (!value) return undefined;
  const date = typeof value === 'string' ? new Date(value) : value;
  if (Number.isNaN(date.getTime())) return undefined;
  return date.toISOString().split('T')[0];
};

const mapRecordToDTO = (record: POItemRecord): PurchaseOrderItemDTO => ({
  IsIncomplete: record.isIncomplete ?? true,
  StyleCode: record.styleCode ?? '',
  ItemRefNo: record.itemRefNo ?? '',
  ItemPoNo: record.itemPoNo ?? '',
  ChandraItemCode: record.chandraItemCode ?? '',
  OrderQty: record.orderQty ?? 0,
  Metal: record.metal ?? '',
  Tone: record.tone ?? '',
  Category: record.category ?? '',
  StockType: record.stockType ?? null,
  MakeType: record.makeType ?? null,
  CustomerProductionInstruction: record.customerProductionInstruction ?? null,
  SpecialRemarks: record.specialRemarks ?? null,
  DesignProductionInstruction: record.designProductionInstruction ?? null,
  StampInstruction: record.stampInstruction ?? null,
  ItemSize: record.itemSize ?? null,
  DeadlineDate: formatDateForClient(record.deadlineDate ?? null) ?? null,
  ShippingDate: formatDateForClient(record.shippingDate ?? null) ?? null,
  InvoiceNumber: record.invoiceNumber ?? '',
});

const mapDTOToRecord = (item: PurchaseOrderItemDTO): POItemRecord => ({
  isIncomplete: Boolean(item.IsIncomplete ?? true),
  styleCode: item.StyleCode || '',
  itemRefNo: item.ItemRefNo || '',
  itemPoNo: item.ItemPoNo || '',
  chandraItemCode: item.ChandraItemCode || '',
  orderQty: Number(item.OrderQty) || 0,
  metal: item.Metal || '',
  tone: item.Tone || '',
  category: item.Category || '',
  stockType: item.StockType ?? null,
  makeType: item.MakeType ?? null,
  customerProductionInstruction: item.CustomerProductionInstruction ?? null,
  specialRemarks: item.SpecialRemarks ?? null,
  designProductionInstruction: item.DesignProductionInstruction ?? null,
  stampInstruction: item.StampInstruction ?? null,
  itemSize: item.ItemSize ?? null,
  deadlineDate: normalizeDate(item.DeadlineDate ?? undefined) ?? null,
  shippingDate: normalizeDate(item.ShippingDate ?? undefined) ?? null,
  invoiceNumber: item.InvoiceNumber || '',
});

const mapDocToDTO = (po: any): PurchaseOrderDTO => {
  // Handle populated references - if item has styleCode, it's populated; if it's just an ObjectId, skip it
  const autoGeneratedItems = Array.isArray(po.autoGeneratedContent) 
    ? po.autoGeneratedContent
        .filter((item: any) => item && typeof item === 'object' && 'styleCode' in item)
        .map((item: any) => ({
          isIncomplete: item.isIncomplete ?? true,
          styleCode: item.styleCode ?? '',
          itemRefNo: item.itemRefNo ?? '',
          itemPoNo: item.itemPoNo ?? '',
          chandraItemCode: item.chandraItemCode ?? '',
          orderQty: item.orderQty ?? 0,
          metal: item.metal ?? '',
          tone: item.tone ?? '',
          category: item.category ?? '',
          stockType: item.stockType ?? null,
          makeType: item.makeType ?? null,
          customerProductionInstruction: item.customerProductionInstruction ?? null,
          specialRemarks: item.specialRemarks ?? null,
          designProductionInstruction: item.designProductionInstruction ?? null,
          stampInstruction: item.stampInstruction ?? null,
          itemSize: item.itemSize ?? null,
          deadlineDate: item.deadlineDate ?? null,
          shippingDate: item.shippingDate ?? null,
          invoiceNumber: item.invoiceNumber ?? '',
        }))
        .map(mapRecordToDTO)
    : [];
  
  const items = Array.isArray(po.items)
    ? po.items
        .filter((item: any) => item && typeof item === 'object' && 'styleCode' in item)
        .map((item: any) => ({
          isIncomplete: item.isIncomplete ?? true,
          styleCode: item.styleCode ?? '',
          itemRefNo: item.itemRefNo ?? '',
          itemPoNo: item.itemPoNo ?? '',
          chandraItemCode: item.chandraItemCode ?? '',
          orderQty: item.orderQty ?? 0,
          metal: item.metal ?? '',
          tone: item.tone ?? '',
          category: item.category ?? '',
          stockType: item.stockType ?? null,
          makeType: item.makeType ?? null,
          customerProductionInstruction: item.customerProductionInstruction ?? null,
          specialRemarks: item.specialRemarks ?? null,
          designProductionInstruction: item.designProductionInstruction ?? null,
          stampInstruction: item.stampInstruction ?? null,
          itemSize: item.itemSize ?? null,
          deadlineDate: item.deadlineDate ?? null,
          shippingDate: item.shippingDate ?? null,
          invoiceNumber: item.invoiceNumber ?? '',
        }))
        .map(mapRecordToDTO)
    : [];

  return {
    PONumber: po.poNumber,
    PODate: formatDateForClient(po.poDate) || '',
    ClientName: po.clientName,
    TotalItems: po.totalItems,
    IncompleteItems: po.incompleteItems,
    TotalValue: po.totalValue,
    Status: po.status,
    AutoGeneratedContent: autoGeneratedItems,
    Items: items,
    PO: po.poFiles?.map((file: FileMetadata) => file.path) ?? [],
    Invoices: po.invoices ?? [],
    ClientReminderCount: po.clientReminderCount ?? 0,
  };
};

const mapDTOToDoc = async (dto: PurchaseOrderDTO): Promise<Partial<any>> => {
  /**
   * Persist all reviewed items into `autoGeneratedContent`
   * and only the completed ones (IsIncomplete === false) into `items`.
   *
   * We intentionally derive from `AutoGeneratedContent` only, because the
   * frontend currently sends both `Items` and `AutoGeneratedContent` as the
   * full reviewed list. Using a single source of truth avoids duplication
   * issues and ensures that the `items` array behaves as:
   *   - a subset of `autoGeneratedContent`
   *   - containing only completed items for downstream processing / hsort.
   */

  const allItemRecords = (dto.AutoGeneratedContent ?? []).map(mapDTOToRecord);

  // Create POItem documents once for all items
  const createdItems = await Promise.all(
    allItemRecords.map(async (record) => {
      const item = await POItem.create(record);
      return item;
    }),
  );

  const autoGeneratedIds = createdItems.map((item) => item._id);
  const completedIds = createdItems
    .filter((item) => !item.isIncomplete)
    .map((item) => item._id);

  const totalItems = allItemRecords.length;
  const incompleteItems =
    allItemRecords.filter((item) => item.isIncomplete).length;

  return {
    poNumber: dto.PONumber,
    poDate: normalizeDate(dto.PODate) ?? new Date(),
    clientName: dto.ClientName,
    totalItems,
    incompleteItems,
    totalValue: dto.TotalValue ?? 0,
    status: dto.Status || 'New',
    autoGeneratedContent: autoGeneratedIds,
    items: completedIds,
    invoices: dto.Invoices ?? [],
    clientReminderCount: dto.ClientReminderCount ?? 0,
  };
};

const mapExtractionLineToRecord = (line: ExtractedLine, invoiceNumber?: string): POItemRecord => ({
  isIncomplete: true, // Default to true as per requirements
  styleCode: line.StyleCode || '',
  itemRefNo: line.ItemRefNo || '',
  itemPoNo: line.ItemPoNo || '',
  chandraItemCode: line.ItemRefNo || '', // Using ItemRefNo as ChandraItemCode
  orderQty: Number(line.OrderQty) || 0,
  metal: line.Metal || '',
  tone: line.Tone || '',
  category: line.Category || '',
  stockType: line.StockType ?? null,
  makeType: line.MakeType ?? null,
  customerProductionInstruction: line.CustomerProductionInstruction ?? null,
  specialRemarks: line.SpecialRemarks ?? null,
  designProductionInstruction: line.DesignProductionInstruction ?? null,
  stampInstruction: line.StampInstruction ?? null,
  itemSize: line.ItemSize !== undefined && line.ItemSize !== null ? String(line.ItemSize) : null,
  deadlineDate: null,
  shippingDate: null,
  invoiceNumber: invoiceNumber || '',
});

const buildPOFromExtraction = async (extraction: ExtractedPOResponse, fileMeta: FileMetadata): Promise<any> => {
  // Map FastAPI items to POItem records (all items go to auto_generated_content)
  const itemRecords = (extraction.items || []).map((line) => mapExtractionLineToRecord(line, extraction.invoice_number));
  
  // Create POItem documents in database and get their ObjectIds
  const autoGeneratedItemIds = await Promise.all(
    itemRecords.map(async (record) => {
      const item = await POItem.create(record);
      return item._id;
    })
  );

  const poNumber = extraction.invoice_number?.trim() || generatePoNumberFromFilename(fileMeta.filename);
  const poDate = extraction.invoice_date ? normalizeDate(extraction.invoice_date) ?? new Date() : new Date();

  return {
    poNumber,
    poDate: poDate || new Date(),
    clientName: extraction.client_name || 'Unknown Client',
    totalItems: itemRecords.length,
    incompleteItems: itemRecords.filter((item) => item.isIncomplete).length,
    totalValue: Number(extraction.total_value) || 0,
    status: 'New',
    autoGeneratedContent: autoGeneratedItemIds, // All items from FastAPI
    items: [], // Empty array as per requirements
    poFiles: [fileMeta],
    invoices: extraction.invoice_number ? [extraction.invoice_number] : [],
    clientReminderCount: 0,
  };
};

const generatePoNumberFromFilename = (filename: string) => {
  const timestamp = Date.now();
  const sanitized = filename.replace(/\.[^/.]+$/, '').replace(/[^a-zA-Z0-9-_]/g, '-');
  return `${sanitized || 'PO'}-${timestamp}`;
};

const upsertFileMetadata = async (meta: FileMetadata) => {
  const savedFile = await File.create(meta);
  return {
    key: savedFile.key,
    path: savedFile.path,
    filename: savedFile.filename,
    createdAt: savedFile.createdAt,
    updatedAt: savedFile.updatedAt,
  };
};

export const getPOs = async (_req: Request, res: Response) => {
  try {
    const pos = await PO.find()
      .populate('autoGeneratedContent')
      .populate('items')
      .sort({ poDate: -1 });
    const response = pos.map((poDoc: any) => mapDocToDTO(poDoc.toObject()));
    res.status(200).json(response);
  } catch (error) {
    console.error('Error fetching POs:', error);
    res.status(500).json({ message: 'Failed to fetch POs' });
  }
};

export const getPOByNumber = async (req: Request, res: Response) => {
  try {
    const po = await PO.findOne({ poNumber: req.params.poNumber })
      .populate('autoGeneratedContent')
      .populate('items');
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }
    res.status(200).json(mapDocToDTO(po.toObject()));
  } catch (error) {
    console.error('Error fetching PO:', error);
    res.status(500).json({ message: 'Failed to fetch PO' });
  }
};

export const updatePO = async (req: Request, res: Response) => {
  try {
    const dto = req.body as PurchaseOrderDTO;
    if (dto?.PONumber && dto.PONumber !== req.params.poNumber) {
      return res.status(400).json({ message: 'PO number mismatch' });
    }
    const update = await mapDTOToDoc(dto);
    const po = await PO.findOneAndUpdate({ poNumber: req.params.poNumber }, update, { new: true })
      .populate('autoGeneratedContent')
      .populate('items');
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }
    res.status(200).json(mapDocToDTO(po.toObject()));
  } catch (error) {
    console.error('Error updating PO:', error);
    res.status(500).json({ message: 'Failed to update PO' });
  }
};

export const uploadPO = async (req: Request, res: Response) => {
  let uploadResult: { key: string; url: string; bucket: string } | null = null;
  let fileMeta: FileMetadata | null = null;

  try {
    const file = req.file as Express.Multer.File | undefined;
    if (!file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }

    // Upload file to S3
    uploadResult = await s3Service.uploadFile(file.buffer, file.originalname, file.mimetype, 'pos');
    fileMeta = await upsertFileMetadata({
      key: uploadResult.key,
      path: uploadResult.url,
      filename: file.originalname,
    });

    // Extract purchase order data from FastAPI
    const extraction = await fastapiService.extractPurchaseOrder(file);
    const poPayload = await buildPOFromExtraction(extraction, fileMeta);

    let existing = await PO.findOne({ poNumber: poPayload.poNumber });

    if (existing) {
      // `existing.poFiles` is backed by the Mongoose `File` model; cast to our shared
      // `FileMetadata` shape for type-safe comparison and merging.
      const existingFiles = (existing.poFiles || []) as unknown as FileMetadata[];
      const fileAlreadyLinked = existingFiles.some(
        (entry) => entry.key === fileMeta!.key,
      );
      if (!fileAlreadyLinked) {
        existing.poFiles = ([...(existing.poFiles || []), fileMeta] as unknown) as typeof existing.poFiles;
      }

      existing.poDate = poPayload.poDate;
      existing.clientName = poPayload.clientName;
      existing.totalItems = poPayload.totalItems;
      existing.incompleteItems = poPayload.incompleteItems;
      existing.totalValue = poPayload.totalValue;
      existing.status = 'New';
      existing.autoGeneratedContent = poPayload.autoGeneratedContent;
      existing.items = poPayload.items; // Empty array
      existing.invoices = Array.from(new Set([...(existing.invoices || []), ...poPayload.invoices]));
      existing.clientReminderCount = existing.clientReminderCount ?? 0;

      await existing.save();
      await existing.populate('autoGeneratedContent');
      await existing.populate('items');
    } else {
      existing = await PO.create(poPayload);
      await existing.populate('autoGeneratedContent');
      await existing.populate('items');
    }

    res.status(201).json({
      message: 'PO uploaded and processed successfully',
      po: mapDocToDTO(existing.toObject()),
    });
  } catch (error) {
    console.error('Error in uploadPO:', error);

    // Clean up: Delete file from S3 if upload succeeded but processing failed
    if (uploadResult?.key) {
      try {
        await s3Service.deleteAsset(uploadResult.key, uploadResult.bucket || undefined);
        console.log(`Deleted file from S3: ${uploadResult.key}`);
      } catch (deleteError) {
        console.error(`Failed to delete file from S3 (${uploadResult.key}):`, deleteError);
        // Don't throw - we still want to return the original error
      }
    }

    // Clean up: Delete file metadata from database if it was created
    if (fileMeta?.key) {
      try {
        await File.findOneAndDelete({ key: fileMeta.key });
        console.log(`Deleted file metadata from database: ${fileMeta.key}`);
      } catch (deleteError) {
        console.error(`Failed to delete file metadata from database (${fileMeta.key}):`, deleteError);
        // Don't throw - we still want to return the original error
      }
    }

    res.status(500).json({ message: 'Failed to upload PO', error: (error as Error).message });
  }
};

const resolveLegacyFilePath = (filePath: string) => {
  if (filePath.startsWith('uploads/')) {
    return path.resolve(process.cwd(), 'apps/api', filePath);
  }
  if (path.isAbsolute(filePath)) {
    return filePath;
  }
  return path.resolve(process.cwd(), filePath);
};

const parseS3Url = (url: string): { bucket: string; key: string } | null => {
  try {
    // Handle S3 URLs like: https://bucket.s3.region.amazonaws.com/key
    // or https://s3.region.amazonaws.com/bucket/key
    const urlObj = new URL(url);
    
    // Pattern 1: https://bucket.s3.region.amazonaws.com/key
    const bucketMatch = urlObj.hostname.match(/^([^.]+)\.s3[.-](.+?)\.amazonaws\.com$/);
    if (bucketMatch) {
      const bucket = bucketMatch[1];
      const key = decodeURIComponent(urlObj.pathname.substring(1)); // Remove leading /
      return { bucket, key };
    }
    
    // Pattern 2: https://s3.region.amazonaws.com/bucket/key
    if (urlObj.hostname.includes('s3') && urlObj.hostname.includes('amazonaws.com')) {
      const pathParts = urlObj.pathname.substring(1).split('/');
      if (pathParts.length >= 2) {
        const bucket = pathParts[0];
        const key = decodeURIComponent(pathParts.slice(1).join('/'));
        return { bucket, key };
      }
    }
    
    return null;
  } catch (error) {
    console.error('Error parsing S3 URL:', error);
    return null;
  }
};

export const streamPOPdf = async (req: Request, res: Response) => {
  try {
    const fileParam = (req.query.file as string) || '';
    if (!fileParam) {
      return res.status(400).json({ message: 'File parameter is required' });
    }

    const po = await PO.findOne({ poNumber: req.params.poNumber });
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }

    // `po.poFiles` comes from the Mongoose model and is not strongly typed as `FileMetadata[]`,
    // so we cast it through `unknown` here to align with our shared `FileMetadata` shape.
    const files = (po.poFiles || []) as unknown as FileMetadata[];
    const matchingFile =
      files.find(
        (file) => file.path === fileParam || file.key === fileParam,
      ) ?? null;
    const targetPath = matchingFile?.path || matchingFile?.key || fileParam;

    // Handle S3 URLs - fetch and proxy instead of redirecting
    if (/^https?:\/\//i.test(targetPath)) {
      const s3Info = parseS3Url(targetPath);
      if (s3Info) {
        try {
          const s3Client = new S3Client({
            region: process.env.AWS_REGION || 'eu-north-1',
            credentials: {
              accessKeyId: process.env.AWS_ACCESS_KEY_ID || '',
              secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || '',
            },
          });

          const command = new GetObjectCommand({
            Bucket: s3Info.bucket,
            Key: s3Info.key,
          });

          const response = await s3Client.send(command);
          
          if (!response.Body) {
            return res.status(500).json({ message: 'Failed to fetch file from S3' });
          }

          res.setHeader('Content-Type', response.ContentType || 'application/pdf');
          res.setHeader('Content-Disposition', `inline; filename="${path.basename(s3Info.key)}"`);
          
          // Stream the S3 object to the response
          // Body is a Readable stream in AWS SDK v3
          const stream = response.Body as any;
          if (stream.pipe) {
            stream.pipe(res);
          } else {
            // Fallback: convert to buffer if stream doesn't have pipe method
            const chunks: Uint8Array[] = [];
            for await (const chunk of stream) {
              chunks.push(chunk);
            }
            const buffer = Buffer.concat(chunks);
            res.send(buffer);
          }
          
          return;
        } catch (s3Error) {
          console.error('Error fetching from S3:', s3Error);
          return res.status(500).json({ message: 'Failed to fetch file from S3' });
        }
      }
      
      // If it's an HTTP/HTTPS URL but not S3, try to redirect (might be a public URL)
      // But for security, we'll return an error instead
      return res.status(400).json({ message: 'Direct URL access not supported. Please use S3 or local file paths.' });
    }

    // Handle local file paths
    const absolutePath = resolveLegacyFilePath(targetPath);
    if (!fs.existsSync(absolutePath)) {
      return res.status(404).json({ message: 'PDF file not found' });
    }

    res.setHeader('Content-Type', 'application/pdf');
    res.setHeader('Content-Disposition', `inline; filename="${path.basename(absolutePath)}"`);
    fs.createReadStream(absolutePath).pipe(res);
  } catch (error) {
    console.error('Error streaming PO pdf:', error);
    res.status(500).json({ message: 'Failed to fetch PO PDF' });
  }
};

export default { getPOs, getPOByNumber, updatePO, uploadPO, streamPOPdf };