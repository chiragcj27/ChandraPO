import { Request, Response } from 'express';
import fs from 'fs';
import path from 'path';
import { S3Client, GetObjectCommand } from '@aws-sdk/client-s3';
import { File, PO, POItem, Client } from '@repo/db';
import { s3Service } from '../services/s3.service';
import { fastapiService } from '../services/fastapi.service';
import type { AuthRequest } from '../middleware/auth.middleware';
import type {
  ExtractedLine,
  ExtractedPOResponse,
  FileMetadata,
  PODocumentShape,
  POItemRecord,
  PurchaseOrderDTO,
  PurchaseOrderItemDTO,
} from '../types/po';

const normalizeDate = (value?: string | Date | null) => {
  if (!value) return undefined;
  const date = typeof value === 'string' ? new Date(value) : value;
  if (Number.isNaN(date.getTime())) return undefined;
  return date;
};

const formatDateForClient = (value?: Date | string | null) => {
  if (!value) return undefined;
  const date = typeof value === 'string' ? new Date(value) : value;
  if (Number.isNaN(date.getTime())) return undefined;
  return date.toISOString().split('T')[0];
};

const mapRecordToDTO = (record: POItemRecord, completedByUser?: any): PurchaseOrderItemDTO => {
  const completedByName = completedByUser 
    ? (completedByUser.username || completedByUser.name || completedByUser.email || null)
    : null;
  
  return {
    IsIncomplete: record.isIncomplete ?? true,
    VendorStyleCode: record.vendorStyleCode ?? '',
    ItemRefNo: record.itemRefNo ?? '',
    ItemPoNo: record.itemPoNo ?? '',
    OrderQty: record.orderQty ?? 0,
    Metal: record.metal ?? '',
    Tone: record.tone ?? '',
    Category: record.category ?? '',
    StockType: record.stockType ?? null,
    MakeType: record.makeType ?? null,
    CustomerProductionInstruction: record.customerProductionInstruction ?? null,
    SpecialRemarks: record.specialRemarks ?? null,
    DesignProductionInstruction: record.designProductionInstruction ?? null,
    StampInstruction: record.stampInstruction ?? null,
    ItemSize: record.itemSize ?? null,
    DeadlineDate: formatDateForClient(record.deadlineDate ?? null) ?? null,
    ShippingDate: formatDateForClient(record.shippingDate ?? null) ?? null,
    InvoiceNumber: record.invoiceNumber ?? '',
    ExportedToExcel: record.exportedToExcel ?? false,
    CompletedBy: record.completedBy ?? null,
    CompletedByName: completedByName,
  };
};

const mapDTOToRecord = (item: PurchaseOrderItemDTO, completedByUserId?: string | null): POItemRecord => ({
  isIncomplete: Boolean(item.IsIncomplete ?? true),
  vendorStyleCode: item.VendorStyleCode || '',
  itemRefNo: item.ItemRefNo || '',
  itemPoNo: item.ItemPoNo || '',
  orderQty: Number(item.OrderQty) || 0,
  metal: item.Metal || '',
  tone: item.Tone || '',
  category: item.Category || '',
  stockType: item.StockType ?? null,
  makeType: item.MakeType ?? null,
  customerProductionInstruction: item.CustomerProductionInstruction ?? null,
  specialRemarks: item.SpecialRemarks ?? null,
  designProductionInstruction: item.DesignProductionInstruction ?? null,
  stampInstruction: item.StampInstruction ?? null,
  itemSize: item.ItemSize ?? null,
  deadlineDate: normalizeDate(item.DeadlineDate ?? undefined) ?? null,
  shippingDate: normalizeDate(item.ShippingDate ?? undefined) ?? null,
  invoiceNumber: item.InvoiceNumber || '',
  exportedToExcel: Boolean(item.ExportedToExcel ?? false),
  completedBy: completedByUserId ?? null,
});

const mapDocToDTO = (po: any): PurchaseOrderDTO => {
  // Handle populated references - if item has vendorStyleCode, it's populated; if it's just an ObjectId, skip it
  const autoGeneratedItems = Array.isArray(po.autoGeneratedContent) 
    ? po.autoGeneratedContent
        .filter((item: any) => item && typeof item === 'object' && 'vendorStyleCode' in item)
        .map((item: any) => {
          const record: POItemRecord = {
            isIncomplete: item.isIncomplete ?? true,
            vendorStyleCode: item.vendorStyleCode ?? '',
            itemRefNo: item.itemRefNo ?? '',
            itemPoNo: item.itemPoNo ?? '',
            orderQty: item.orderQty ?? 0,
            metal: item.metal ?? '',
            tone: item.tone ?? '',
            category: item.category ?? '',
            stockType: item.stockType ?? null,
            makeType: item.makeType ?? null,
            customerProductionInstruction: item.customerProductionInstruction ?? null,
            specialRemarks: item.specialRemarks ?? null,
            designProductionInstruction: item.designProductionInstruction ?? null,
            stampInstruction: item.stampInstruction ?? null,
            itemSize: item.itemSize ?? null,
            deadlineDate: item.deadlineDate ?? null,
            shippingDate: item.shippingDate ?? null,
            invoiceNumber: item.invoiceNumber ?? '',
            exportedToExcel: item.exportedToExcel ?? false,
            completedBy: item.completedBy 
              ? (typeof item.completedBy === 'object' 
                ? ('_id' in item.completedBy ? item.completedBy._id.toString() : item.completedBy.toString())
                : item.completedBy.toString())
              : null,
          };
          // Get populated completedBy user if available (has email field means it's populated)
          const completedByUser = item.completedBy && typeof item.completedBy === 'object' && 'email' in item.completedBy
            ? item.completedBy
            : null;
          return mapRecordToDTO(record, completedByUser);
        })
    : [];
  
  const items = Array.isArray(po.items)
    ? po.items
        .filter((item: any) => item && typeof item === 'object' && 'vendorStyleCode' in item)
        .map((item: any) => {
          const record: POItemRecord = {
            isIncomplete: item.isIncomplete ?? true,
            vendorStyleCode: item.vendorStyleCode ?? '',
            itemRefNo: item.itemRefNo ?? '',
            itemPoNo: item.itemPoNo ?? '',
            orderQty: item.orderQty ?? 0,
            metal: item.metal ?? '',
            tone: item.tone ?? '',
            category: item.category ?? '',
            stockType: item.stockType ?? null,
            makeType: item.makeType ?? null,
            customerProductionInstruction: item.customerProductionInstruction ?? null,
            specialRemarks: item.specialRemarks ?? null,
            designProductionInstruction: item.designProductionInstruction ?? null,
            stampInstruction: item.stampInstruction ?? null,
            itemSize: item.itemSize ?? null,
            deadlineDate: item.deadlineDate ?? null,
            shippingDate: item.shippingDate ?? null,
            invoiceNumber: item.invoiceNumber ?? '',
            exportedToExcel: item.exportedToExcel ?? false,
            completedBy: item.completedBy 
              ? (typeof item.completedBy === 'object' 
                ? ('_id' in item.completedBy ? item.completedBy._id.toString() : item.completedBy.toString())
                : item.completedBy.toString())
              : null,
          };
          // Get populated completedBy user if available (has email field means it's populated)
          const completedByUser = item.completedBy && typeof item.completedBy === 'object' && 'email' in item.completedBy
            ? item.completedBy
            : null;
          return mapRecordToDTO(record, completedByUser);
        })
    : [];

  return {
    PONumber: po.poNumber,
    PODate: formatDateForClient(po.poDate) || '',
    ClientName: po.clientName,
    TotalItems: po.totalItems,
    IncompleteItems: po.incompleteItems,
    TotalValue: po.totalValue,
    Status: po.status,
    AutoGeneratedContent: autoGeneratedItems,
    Items: items,
    PO: po.poFiles?.map((file: FileMetadata) => file.path) ?? [],
    Invoices: po.invoices ?? [],
    ClientReminderCount: po.clientReminderCount ?? 0,
  };
};

const mapDTOToDoc = async (dto: PurchaseOrderDTO, existingItems?: any[], currentUserId?: string | null): Promise<Partial<any>> => {
  /**
   * Persist all reviewed items into `autoGeneratedContent`
   * and only the completed ones (IsIncomplete === false) into `items`.
   *
   * We intentionally derive from `AutoGeneratedContent` only, because the
   * frontend currently sends both `Items` and `AutoGeneratedContent` as the
   * full reviewed list. Using a single source of truth avoids duplication
   * issues and ensures that the `items` array behaves as:
   *   - a subset of `autoGeneratedContent`
   *   - containing only completed items for downstream processing / hsort.
   */

  const allItemRecords = (dto.AutoGeneratedContent ?? []).map((item, index) => {
    const existingItem = existingItems?.[index];
    // If item is being marked as complete (was incomplete, now complete), set completedBy
    const wasIncomplete = existingItem?.isIncomplete ?? true;
    const isNowComplete = !item.IsIncomplete;
    const shouldSetCompletedBy = wasIncomplete && isNowComplete && currentUserId;
    
    return mapDTOToRecord(item, shouldSetCompletedBy ? currentUserId : (existingItem?.completedBy?.toString() || null));
  });

  // If existing items are provided, update them instead of creating new ones
  // This preserves the exportedToExcel flag and other metadata
  let createdItems: any[];
  
  if (existingItems && existingItems.length > 0) {
    // Update existing items, matching by position in the array
    createdItems = await Promise.all(
      allItemRecords.map(async (record, index) => {
        const existingItem = existingItems[index];
        if (existingItem && existingItem._id) {
          // Preserve exportedToExcel from existing item if it's already exported
          // Only update if the new record explicitly sets it to true
          const preservedExportedToExcel = existingItem.exportedToExcel ?? false;
          const newExportedToExcel = record.exportedToExcel ?? false;
          
          // Update the existing item
          const updatedRecord = {
            ...record,
            // Preserve exportedToExcel flag: once exported, it stays exported unless item is marked incomplete
            exportedToExcel: record.isIncomplete ? false : (preservedExportedToExcel || newExportedToExcel),
          };
          
          const updated = await POItem.findByIdAndUpdate(
            existingItem._id,
            updatedRecord,
            { new: true }
          );
          return updated || await POItem.create(updatedRecord);
        } else {
          // No existing item at this position, create new one
          return await POItem.create(record);
        }
      }),
    );
    
    // Handle case where new items are added (more items than existing)
    if (allItemRecords.length > existingItems.length) {
      const newItems = await Promise.all(
        allItemRecords.slice(existingItems.length).map(async (record) => {
          return await POItem.create(record);
        }),
      );
      createdItems = [...createdItems, ...newItems];
    }
  } else {
    // No existing items, create new ones
    createdItems = await Promise.all(
      allItemRecords.map(async (record) => {
        const item = await POItem.create(record);
        return item;
      }),
    );
  }

  const autoGeneratedIds = createdItems.map((item: any) => item._id);
  const completedIds = createdItems
    .filter((item: any) => !item.isIncomplete)
    .map((item: any) => item._id);

  const totalItems = allItemRecords.length;
  const incompleteItems =
    allItemRecords.filter((item) => item.isIncomplete).length;

  return {
    poNumber: dto.PONumber,
    poDate: normalizeDate(dto.PODate) ?? new Date(),
    clientName: dto.ClientName,
    totalItems,
    incompleteItems,
    totalValue: dto.TotalValue ?? 0,
    status: dto.Status || 'New',
    autoGeneratedContent: autoGeneratedIds,
    items: completedIds,
    invoices: dto.Invoices ?? [],
    clientReminderCount: dto.ClientReminderCount ?? 0,
  };
};

// Normalize enum values to match dropdown options exactly
const normalizeMetal = (value: string | null | undefined): string => {
  if (!value) return '';
  const normalized = value.trim();
  const metalMap: Record<string, string> = {
    'G09KT': 'G09KT', 'G10KT': 'G10KT', 'G14KT': 'G14KT', 'G18KT': 'G18KT', '950': '950', 'SV925': 'SV925',
    '9KT': 'G09KT', '10KT': 'G10KT', '14K': 'G14KT', '18K': 'G18KT',
    'PLATINUM': '950', 'PT950': '950', 'SILVER': 'SV925', '925': 'SV925',
  };
  return metalMap[normalized.toUpperCase()] || normalized;
};

const normalizeTone = (value: string | null | undefined): string => {
  if (!value) return '';
  const normalized = value.trim().toUpperCase();
  const toneMap: Record<string, string> = {
    'Y': 'Y', 'R': 'R', 'W': 'W', 'YW': 'YW', 'RW': 'RW', 'RY': 'RY',
    'YELLOW': 'Y', 'ROSE': 'R', 'WHITE': 'W',
    'YELLOW WHITE': 'YW', 'Y/W': 'YW', 'YELLOW-WHITE': 'YW',
    'ROSE WHITE': 'RW', 'R/W': 'RW', 'ROSE-WHITE': 'RW',
    'ROSE YELLOW': 'RY', 'R/Y': 'RY', 'ROSE-YELLOW': 'RY',
  };
  return toneMap[normalized] || value.trim();
};

const normalizeStockType = (value: string | null | undefined): string | null => {
  if (!value) return null;
  const normalized = value.trim();
  // Exact match first
  const stockTypes = [
    'Studded Gold Jewellery IC', 'Studded Platinum Jewellery IC', 'Plain Gold Jewellery IC',
    'Plain Platinum Jewellery IC', 'Studded Semi Mount Gold Jewellery IC', 'Studded Silver Jewellery IC',
    'Plain Silver Jewellery IC', 'Studded Semi Mount Platinum Jewellery IC', 'Gold Mount Jewellery IC',
    'Studded Combination Jewellery IC',
  ];
  if (stockTypes.includes(normalized)) return normalized;
  // Case-insensitive match
  const upperNormalized = normalized.toUpperCase();
  const match = stockTypes.find(st => st.toUpperCase() === upperNormalized);
  return match || null;
};

const normalizeCategory = (value: string | null | undefined): string => {
  if (!value) return '';
  const normalized = value.trim();
  const categories = ['Ring', 'Band', 'Pendant', 'Necklace', 'Bracelet'];
  // Exact match first
  if (categories.includes(normalized)) return normalized;
  // Case-insensitive match
  const upperNormalized = normalized.toUpperCase();
  const match = categories.find(cat => cat.toUpperCase() === upperNormalized);
  return match || ''; // Return empty string if no match found, so dropdown shows "Select category"
};

const normalizeMakeType = (value: string | null | undefined): string | null => {
  if (!value) return null;
  const normalized = value.trim();
  const makeTypes = ['CNC', 'HOLLOW TUBING', '1 PC CAST', '2 PC CAST', 'MULTI CAST', 'HIP HOP'];
  if (makeTypes.includes(normalized)) return normalized;
  // Case-insensitive match
  const upperNormalized = normalized.toUpperCase();
  const match = makeTypes.find(mt => mt.toUpperCase() === upperNormalized);
  return match || null;
};

const mapExtractionLineToRecord = (line: ExtractedLine, invoiceNumber?: string): POItemRecord => ({
  isIncomplete: true, // Default to true as per requirements
  vendorStyleCode: (line.VendorStyleCode || '').trim(),
  itemRefNo: (line.ItemRefNo || '').trim(),
  itemPoNo: (line.ItemPoNo || '').trim(),
  orderQty: Number(line.OrderQty) || 0,
  metal: normalizeMetal(line.Metal),
  tone: normalizeTone(line.Tone),
  category: normalizeCategory(line.Category),
  stockType: normalizeStockType(line.StockType),
  makeType: normalizeMakeType(line.MakeType),
  customerProductionInstruction: line.CustomerProductionInstruction ? line.CustomerProductionInstruction.trim() : null,
  specialRemarks: line.SpecialRemarks ? line.SpecialRemarks.trim() : null,
  designProductionInstruction: line.DesignProductionInstruction ? line.DesignProductionInstruction.trim() : null,
  stampInstruction: line.StampInstruction ? line.StampInstruction.trim() : null,
  itemSize: line.ItemSize !== undefined && line.ItemSize !== null ? String(line.ItemSize).trim() : null,
  deadlineDate: null,
  shippingDate: null,
  invoiceNumber: (invoiceNumber || '').trim(),
  exportedToExcel: false, // New items are never exported
});

const buildPOFromExtraction = async (
  extraction: ExtractedPOResponse,
  fileMeta: FileMetadata,
  clientNameOverride?: string,
): Promise<any> => {
  // Map FastAPI items to POItem records (all items go to auto_generated_content)
  const itemRecords = (extraction.items || []).map((line) => mapExtractionLineToRecord(line, extraction.invoice_number));
  
  // Create POItem documents in database and get their ObjectIds
  const autoGeneratedItemIds = await Promise.all(
    itemRecords.map(async (record) => {
      const item = await POItem.create(record);
      return item._id;
    })
  );

  const poNumber = extraction.invoice_number?.trim() || generatePoNumberFromFilename(fileMeta.filename);
  const poDate = extraction.invoice_date ? normalizeDate(extraction.invoice_date) ?? new Date() : new Date();

  return {
    poNumber,
    poDate: poDate || new Date(),
    clientName: clientNameOverride || extraction.client_name || 'Unknown Client',
    totalItems: itemRecords.length,
    incompleteItems: itemRecords.filter((item) => item.isIncomplete).length,
    totalValue: Number(extraction.total_value) || 0,
    status: 'New',
    autoGeneratedContent: autoGeneratedItemIds, // All items from FastAPI
    items: [], // Empty array as per requirements
    poFiles: [fileMeta],
    invoices: extraction.invoice_number ? [extraction.invoice_number] : [],
    clientReminderCount: 0,
  };
};

const generatePoNumberFromFilename = (filename: string) => {
  const timestamp = Date.now();
  const sanitized = filename.replace(/\.[^/.]+$/, '').replace(/[^a-zA-Z0-9-_]/g, '-');
  return `${sanitized || 'PO'}-${timestamp}`;
};

const upsertFileMetadata = async (meta: FileMetadata) => {
  const savedFile = await File.create(meta);
  return {
    key: savedFile.key,
    path: savedFile.path,
    filename: savedFile.filename,
    createdAt: savedFile.createdAt,
    updatedAt: savedFile.updatedAt,
  };
};

export const getPOs = async (req: AuthRequest, res: Response) => {
  try {
    const startRow = parseInt(req.query.startRow as string) || 0;
    const endRow = parseInt(req.query.endRow as string) || 100;
    const limit = endRow - startRow;
    const skip = startRow;

    // Build query based on user role
    let query: any = {};
    
    // If user is a client, filter by client name
    if (req.user?.role === 'client' && req.user.clientId) {
      const client = await Client.findById(req.user.clientId);
      if (client) {
        query.clientName = client.name;
      } else {
        // Client ID exists but client not found - return empty
        res.status(200).json({
          rowData: [],
          rowCount: 0,
        });
        return;
      }
    }
    // Admin users see all POs (empty query)

    // Get total count for infinite scrolling
    const totalCount = await PO.countDocuments(query);

    // Fetch paginated results
    const pos = await PO.find(query)
      .populate({
        path: 'autoGeneratedContent',
        populate: { path: 'completedBy', select: 'name username email' }
      })
      .populate({
        path: 'items',
        populate: { path: 'completedBy', select: 'name username email' }
      })
      .sort({ poDate: -1 })
      .skip(skip)
      .limit(limit);
    
    const response = pos.map((poDoc: any) => mapDocToDTO(poDoc.toObject()));
    
    // Return in format expected by AG Grid infinite row model
    res.status(200).json({
      rowData: response,
      rowCount: totalCount,
    });
  } catch (error) {
    console.error('Error fetching POs:', error);
    res.status(500).json({ message: 'Failed to fetch POs' });
  }
};

export const getPOByNumber = async (req: AuthRequest, res: Response) => {
  try {
    const po = await PO.findOne({ poNumber: req.params.poNumber })
      .populate({
        path: 'autoGeneratedContent',
        populate: { path: 'completedBy', select: 'name username email' }
      })
      .populate({
        path: 'items',
        populate: { path: 'completedBy', select: 'name username email' }
      });
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }

    // Check if client user can access this PO
    if (req.user?.role === 'client' && req.user.clientId) {
      const client = await Client.findById(req.user.clientId);
      if (client && po.clientName !== client.name) {
        return res.status(403).json({ message: 'Access denied. This PO belongs to a different client.' });
      }
    }

    res.status(200).json(mapDocToDTO(po.toObject()));
  } catch (error) {
    console.error('Error fetching PO:', error);
    res.status(500).json({ message: 'Failed to fetch PO' });
  }
};

export const updatePO = async (req: AuthRequest, res: Response) => {
  try {
    // Only admin can update POs
    if (req.user?.role !== 'admin') {
      return res.status(403).json({ message: 'Only admins can update POs. Clients have view-only access.' });
    }

    const dto = req.body as PurchaseOrderDTO;
    if (dto?.PONumber && dto.PONumber !== req.params.poNumber) {
      return res.status(400).json({ message: 'PO number mismatch' });
    }

    // Find existing PO with populated items to preserve exportedToExcel flag
    const existingPO = await PO.findOne({ poNumber: req.params.poNumber })
      .populate('autoGeneratedContent');
    if (!existingPO) {
      return res.status(404).json({ message: 'PO not found' });
    }

    // Get existing items to preserve exportedToExcel flag
    const existingItems = Array.isArray(existingPO.autoGeneratedContent)
      ? existingPO.autoGeneratedContent.filter((item: any) => item && typeof item === 'object' && 'vendorStyleCode' in item)
      : [];

    const currentUserId = req.user?.userId || null;
    const update = await mapDTOToDoc(dto, existingItems, currentUserId);
    const po = await PO.findOneAndUpdate({ poNumber: req.params.poNumber }, update, { new: true })
      .populate({
        path: 'autoGeneratedContent',
        populate: { path: 'completedBy', select: 'name username email' }
      })
      .populate({
        path: 'items',
        populate: { path: 'completedBy', select: 'name username email' }
      });
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }
    res.status(200).json(mapDocToDTO(po.toObject()));
  } catch (error) {
    console.error('Error updating PO:', error);
    res.status(500).json({ message: 'Failed to update PO' });
  }
};

const resolveClientSelection = async (body: any) => {
  const clientId = body?.clientId;
  const clientName = body?.clientName;
  const clientMapping = body?.clientMapping;
  const clientDescription = body?.clientDescription;

  // Existing client by id
  if (clientId) {
    const existing = await Client.findById(clientId);
    if (existing) {
      return { clientName: existing.name, mappingText: existing.mapping };
    }
  }

  // Upsert by name if mapping provided
  if (clientName && clientMapping) {
    const client = await Client.findOneAndUpdate(
      { name: clientName.trim() },
      { name: clientName.trim(), mapping: clientMapping, description: clientDescription ?? null },
      { new: true, upsert: true, setDefaultsOnInsert: true },
    );
    return { clientName: client.name, mappingText: client.mapping };
  }

  return { clientName: clientName ?? null, mappingText: null };
};

export const uploadPO = async (req: AuthRequest, res: Response) => {
  let uploadResult: { key: string; url: string; bucket: string } | null = null;
  let fileMeta: FileMetadata | null = null;

  try {
    // Only admin can upload POs (also enforced by middleware)
    if (req.user?.role !== 'admin') {
      return res.status(403).json({ message: 'Only admins can upload POs' });
    }

    const file = req.file as Express.Multer.File | undefined;
    if (!file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }

    // Upload file to S3
    uploadResult = await s3Service.uploadFile(file.buffer, file.originalname, file.mimetype, 'pos');
    fileMeta = await upsertFileMetadata({
      key: uploadResult.key,
      path: uploadResult.url,
      filename: file.originalname,
    });

    // Resolve client mapping and send it to FastAPI for better extraction
    const { clientName: selectedClientName, mappingText } = await resolveClientSelection(req.body);

    // Parse expected items from request body (optional)
    let expectedItems: number | undefined;
    if (req.body?.expectedItems) {
      const parsed = Number(req.body.expectedItems);
      if (Number.isInteger(parsed) && parsed > 0) {
        expectedItems = parsed;
      }
    }

    // Extract purchase order data from FastAPI
    const extraction = await fastapiService.extractPurchaseOrder(file, {
      clientName: selectedClientName ?? undefined,
      mappingText: mappingText ?? undefined,
      expectedItems,
    });
    const poPayload = await buildPOFromExtraction(extraction, fileMeta, selectedClientName ?? undefined);

    let existing = await PO.findOne({ poNumber: poPayload.poNumber });

    if (existing) {
      // `existing.poFiles` is backed by the Mongoose `File` model; cast to our shared
      // `FileMetadata` shape for type-safe comparison and merging.
      const existingFiles = (existing.poFiles || []) as unknown as FileMetadata[];
      const fileAlreadyLinked = existingFiles.some(
        (entry) => entry.key === fileMeta!.key,
      );
      if (!fileAlreadyLinked) {
        existing.poFiles = ([...(existing.poFiles || []), fileMeta] as unknown) as typeof existing.poFiles;
      }

      existing.poDate = poPayload.poDate;
      existing.clientName = poPayload.clientName;
      existing.totalItems = poPayload.totalItems;
      existing.incompleteItems = poPayload.incompleteItems;
      existing.totalValue = poPayload.totalValue;
      existing.status = 'New';
      existing.autoGeneratedContent = poPayload.autoGeneratedContent;
      existing.items = poPayload.items; // Empty array
      existing.invoices = Array.from(new Set([...(existing.invoices || []), ...poPayload.invoices]));
      existing.clientReminderCount = existing.clientReminderCount ?? 0;

      await existing.save();
      await existing.populate('autoGeneratedContent');
      await existing.populate('items');
    } else {
      existing = await PO.create(poPayload);
      await existing.populate('autoGeneratedContent');
      await existing.populate('items');
    }

    res.status(201).json({
      message: 'PO uploaded and processed successfully',
      po: mapDocToDTO(existing.toObject()),
    });
  } catch (error) {
    console.error('Error in uploadPO:', error);

    // Clean up: Delete file from S3 if upload succeeded but processing failed
    if (uploadResult?.key) {
      try {
        await s3Service.deleteAsset(uploadResult.key, uploadResult.bucket || undefined);
        console.log(`Deleted file from S3: ${uploadResult.key}`);
      } catch (deleteError) {
        console.error(`Failed to delete file from S3 (${uploadResult.key}):`, deleteError);
        // Don't throw - we still want to return the original error
      }
    }

    // Clean up: Delete file metadata from database if it was created
    if (fileMeta?.key) {
      try {
        await File.findOneAndDelete({ key: fileMeta.key });
        console.log(`Deleted file metadata from database: ${fileMeta.key}`);
      } catch (deleteError) {
        console.error(`Failed to delete file metadata from database (${fileMeta.key}):`, deleteError);
        // Don't throw - we still want to return the original error
      }
    }

    res.status(500).json({ message: 'Failed to upload PO', error: (error as Error).message });
  }
};

const resolveLegacyFilePath = (filePath: string) => {
  if (filePath.startsWith('uploads/')) {
    return path.resolve(process.cwd(), 'apps/api', filePath);
  }
  if (path.isAbsolute(filePath)) {
    return filePath;
  }
  return path.resolve(process.cwd(), filePath);
};

const parseS3Url = (url: string): { bucket: string; key: string } | null => {
  try {
    // Handle S3 URLs like: https://bucket.s3.region.amazonaws.com/key
    // or https://s3.region.amazonaws.com/bucket/key
    const urlObj = new URL(url);
    
    // Pattern 1: https://bucket.s3.region.amazonaws.com/key
    const bucketMatch = urlObj.hostname.match(/^([^.]+)\.s3[.-](.+?)\.amazonaws\.com$/);
    if (bucketMatch) {
      const bucket = bucketMatch[1];
      const key = decodeURIComponent(urlObj.pathname.substring(1)); // Remove leading /
      return { bucket, key };
    }
    
    // Pattern 2: https://s3.region.amazonaws.com/bucket/key
    if (urlObj.hostname.includes('s3') && urlObj.hostname.includes('amazonaws.com')) {
      const pathParts = urlObj.pathname.substring(1).split('/');
      if (pathParts.length >= 2) {
        const bucket = pathParts[0];
        const key = decodeURIComponent(pathParts.slice(1).join('/'));
        return { bucket, key };
      }
    }
    
    return null;
  } catch (error) {
    console.error('Error parsing S3 URL:', error);
    return null;
  }
};

const getContentType = (filePath: string): string => {
  const ext = path.extname(filePath).toLowerCase();
  const contentTypes: Record<string, string> = {
    '.pdf': 'application/pdf',
    '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    '.xls': 'application/vnd.ms-excel',
  };
  return contentTypes[ext] || 'application/octet-stream';
};

export const streamPOPdf = async (req: AuthRequest, res: Response) => {
  try {
    const fileParam = (req.query.file as string) || '';
    if (!fileParam) {
      return res.status(400).json({ message: 'File parameter is required' });
    }

    const po = await PO.findOne({ poNumber: req.params.poNumber });
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }

    // Check if client user can access this PO
    if (req.user?.role === 'client' && req.user.clientId) {
      const client = await Client.findById(req.user.clientId);
      if (client && po.clientName !== client.name) {
        return res.status(403).json({ message: 'Access denied. This PO belongs to a different client.' });
      }
    }

    // `po.poFiles` comes from the Mongoose model and is not strongly typed as `FileMetadata[]`,
    // so we cast it through `unknown` here to align with our shared `FileMetadata` shape.
    const files = (po.poFiles || []) as unknown as FileMetadata[];
    const matchingFile =
      files.find(
        (file) => file.path === fileParam || file.key === fileParam,
      ) ?? null;
    const targetPath = matchingFile?.path || matchingFile?.key || fileParam;
    const filename = matchingFile?.filename || path.basename(targetPath);

    // Handle S3 URLs - fetch and proxy instead of redirecting
    if (/^https?:\/\//i.test(targetPath)) {
      const s3Info = parseS3Url(targetPath);
      if (s3Info) {
        try {
          const s3Client = new S3Client({
            region: process.env.AWS_REGION || 'eu-north-1',
            credentials: {
              accessKeyId: process.env.AWS_ACCESS_KEY_ID || '',
              secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || '',
            },
          });

          const command = new GetObjectCommand({
            Bucket: s3Info.bucket,
            Key: s3Info.key,
          });

          const response = await s3Client.send(command);
          
          if (!response.Body) {
            return res.status(500).json({ message: 'Failed to fetch file from S3' });
          }

          const contentType = response.ContentType || getContentType(s3Info.key);
          res.setHeader('Content-Type', contentType);
          res.setHeader('Content-Disposition', `inline; filename="${filename}"`);
          
          // Stream the S3 object to the response
          // Body is a Readable stream in AWS SDK v3
          const stream = response.Body as any;
          if (stream.pipe) {
            stream.pipe(res);
          } else {
            // Fallback: convert to buffer if stream doesn't have pipe method
            const chunks: Uint8Array[] = [];
            for await (const chunk of stream) {
              chunks.push(chunk);
            }
            const buffer = Buffer.concat(chunks);
            res.send(buffer);
          }
          
          return;
        } catch (s3Error) {
          console.error('Error fetching from S3:', s3Error);
          return res.status(500).json({ message: 'Failed to fetch file from S3' });
        }
      }
      
      // If it's an HTTP/HTTPS URL but not S3, try to redirect (might be a public URL)
      // But for security, we'll return an error instead
      return res.status(400).json({ message: 'Direct URL access not supported. Please use S3 or local file paths.' });
    }

    // Handle local file paths
    const absolutePath = resolveLegacyFilePath(targetPath);
    if (!fs.existsSync(absolutePath)) {
      return res.status(404).json({ message: 'File not found' });
    }

    const contentType = getContentType(absolutePath);
    res.setHeader('Content-Type', contentType);
    res.setHeader('Content-Disposition', `inline; filename="${filename}"`);
    fs.createReadStream(absolutePath).pipe(res);
  } catch (error) {
    console.error('Error streaming PO file:', error);
    res.status(500).json({ message: 'Failed to fetch PO file' });
  }
};

export const deletePO = async (req: AuthRequest, res: Response) => {
  try {
    const poNumber = req.params.poNumber;
    
    // Only admin can delete POs
    if (req.user?.role !== 'admin') {
      return res.status(403).json({ message: 'Only admins can delete POs' });
    }
    
    // Find the PO first - don't populate, we'll get IDs directly
    const po = await PO.findOne({ poNumber });
    
    if (!po) {
      return res.status(404).json({ message: 'PO not found' });
    }

    // Get all POItem IDs to delete BEFORE deleting the PO
    // These are stored as ObjectId references in the arrays
    const allItemIds: string[] = [];
    
    // Get IDs from autoGeneratedContent array
    if (Array.isArray(po.autoGeneratedContent) && po.autoGeneratedContent.length > 0) {
      po.autoGeneratedContent.forEach((itemId: any) => {
        if (itemId) {
          // Convert ObjectId to string (works for both ObjectId and string)
          const id = String(itemId);
          if (id && !allItemIds.includes(id)) {
            allItemIds.push(id);
          }
        }
      });
    }
    
    // Get IDs from items array
    if (Array.isArray(po.items) && po.items.length > 0) {
      po.items.forEach((itemId: any) => {
        if (itemId) {
          // Convert ObjectId to string (works for both ObjectId and string)
          const id = String(itemId);
          if (id && !allItemIds.includes(id)) {
            allItemIds.push(id);
          }
        }
      });
    }

    console.log(`Deleting PO ${poNumber}: Found ${allItemIds.length} POItems to delete`);

    // Get all file keys from poFiles for S3 deletion
    const files = (po.poFiles || []) as unknown as FileMetadata[];
    const fileKeys: string[] = [];
    const fileMetadataIds: string[] = [];

    for (const file of files) {
      if (file.key) {
        fileKeys.push(file.key);
      }
      // Try to find File document by key to delete metadata
      const fileDoc = await File.findOne({ key: file.key });
      if (fileDoc) {
        fileMetadataIds.push(fileDoc._id.toString());
      }
    }

    // Delete files from S3
    const s3DeletionPromises = fileKeys.map(async (key) => {
      try {
        // The key is the S3 key, use it directly for deletion
        await s3Service.deleteAsset(key);
      } catch (error) {
        console.error(`Failed to delete S3 file ${key}:`, error);
        // Continue with other deletions even if one fails
      }
    });

    await Promise.allSettled(s3DeletionPromises);

    // Delete File metadata from MongoDB
    const fileMetadataDeletionPromises = fileMetadataIds.map(async (id) => {
      try {
        await File.findByIdAndDelete(id);
      } catch (error) {
        console.error(`Failed to delete file metadata ${id}:`, error);
      }
    });

    await Promise.allSettled(fileMetadataDeletionPromises);

    // Delete all POItems
    const itemDeletionPromises = allItemIds.map(async (id) => {
      try {
        const result = await POItem.findByIdAndDelete(id);
        if (result) {
          console.log(`Successfully deleted POItem ${id}`);
        } else {
          console.warn(`POItem ${id} not found (may have been already deleted)`);
        }
      } catch (error) {
        console.error(`Failed to delete POItem ${id}:`, error);
      }
    });

    const itemDeletionResults = await Promise.allSettled(itemDeletionPromises);
    const deletedCount = itemDeletionResults.filter(r => r.status === 'fulfilled').length;
    console.log(`Deleted ${deletedCount} out of ${allItemIds.length} POItems`);

    // Finally, delete the PO document
    await PO.findByIdAndDelete(po._id);

    res.status(200).json({ 
      message: 'PO deleted successfully',
      poNumber: poNumber 
    });
  } catch (error) {
    console.error('Error deleting PO:', error);
    res.status(500).json({ message: 'Failed to delete PO', error: (error as Error).message });
  }
};

export default { getPOs, getPOByNumber, updatePO, uploadPO, streamPOPdf, deletePO };